---
title: "Sesión 1: Inferencia causal en ciencias sociales"
subtitle: "Técnicas de Evaluación de Impacto de Políticas Públicas en Crimen y Seguridad Ciudadana"
author: 
  - José Conejeros <br> <jdconejeros@sigmaanalytics.cl>
  - Ariel Gonzalez <br> <agonzalez@sigmaanalytics.cl>
  - Javier Fuentes <br> <jfuentes@sigmaanalytics.cl>
  - Hermann Aros <br> <haros@sigmaanalytics.cl>
  - Cristóbal Miño <br> <cmino@sigmaanalytics.cl>
date: last-modified
date-format: 'dddd DD [de] MMMM, YYYY'
last-modified: true
title-block-banner: true
format: 
  html:
    css: "style.css"
    #page-layout: full
    embed-resources: true
    smooth-scroll: true
    fontcolor: black
    toc: true
    toc-location: left
    toc-title: Indice
    code-copy: true
    code-link: true
    code-fold: show
    code-tools: true
    code-summary: "Click para ver el código"
    anchor-sections: true
    code-overflow: wrap
    fig-cap-location: top
lang: es
abstract-title: "Sigma Analytics Spa"
abstract: "[Click al repositorio](https://github.com/SigmaLabsChile/Workshop-IPESA-TEVI24.github.io)"
---

::: logo-position
<!-- No modificar -->
<br><br>
![](images/logo-SA.png){width="200px"}
:::

```{r}
#| echo: false
#| include: false
install.packages("texPreview")
install.packages("dplyr")
install.packages("tidyr")
install.packages("broom")
install.packages("Matrix")
install.packages("AER")
install.packages("tinytex")
install.packages("texreg")
```

Puede saber más de nosotros en: <https://sigmaanalytics.cl/>

## ¿Qué es la inferencia causal? 

Podemos entender la inferencia causal como el interés por estimar el efecto de los acontencimientos y las decisiones sobre un resultado de interés determinado. 

Algunos ejemplos: 

![](images/S1/zubizarreta.png){width="700" height="600" fig-align="center"}

[Zubizarreta, J. R., Cerdá, M., & Rosenbaum, P. R. (2013). Effect of the 2010 Chilean earthquake on posttraumatic stress: reducing sensitivity to unmeasured bias through study design. Epidemiology, 24(1), 79-87.](https://pubmed.ncbi.nlm.nih.gov/23222557/)


![](images/S1/torche.png){width="700" height="700" fig-align="center"}

[Torche, F. (2011). The effect of maternal stress on birth outcomes: exploiting a natural experiment. Demography, 48, 1473-1491.](https://pubmed.ncbi.nlm.nih.gov/21870187/)

![](images/S1/muralidharan.png){width="700" height="600" fig-align="center"}

[Muralidharan, K., Singh, A., & Ganimian, A. J. (2019). Disrupting education? Experimental evidence on technology-aided instruction in India. American Economic Review, 109(4), 1426-1460.](https://www.aeaweb.org/articles?id=10.1257/aer.20171112)

**Fundamental** 

- Datos: **¿Cuál es la estrategia de identificación?** 

- Supuestos: **¿Cuáles son los supuestos que sustentan la causalidad en un estudio?**

Sin embargo, tendremos algunos inconvenientes...

## Problema fundamental de la inferencia causal

Considere una población de $i$ unidades potencialmente expuestas a un tratamiento (causa) o control. La variable $D_i$ nos indicará si la unidad $i$ fue tratada ($D_i=t$) o no tratada, o sea control, ($D_i=c$).

Nos interesa evaluar el efecto sobre una variable de respuesta observada que denotaremos como $Y_i$ con dos respuestas potenciales: 

- $Y_i(t)$ si la unidad fue tratada 
- $Y_i(c)$ en caso contrario 

Dado que $Y_i$ mide el efecto de la causa, entonces, los valores de $Y_i$ son posteriores a la exposición del tratamiento.

A su vez, denotamos que el modelo causal del tratamiento en una unidad $i$ puede ser expresado como:

$$\delta_i=Y_i(t)-Y_i(c)$$

Lo interesante del modelo Neyman-Rubin es que el valor de $D_i$ para cada unidad $i$ podría haber sido distinto. Este es el problema.

$$Y_i=D_iY_i(t)-(1-D_i)Y_i(c)$$
Donde $D_i=1$ si la persona fue tratada y $D_i=0$ en caso contrario, entonces:

$$\delta_i=(1)Y_i(t)-(1-0)Y_i(c)=Y_i(t)-Y_i(c)$$

::: {.callout-important title="Problema fundamental de la inferencia causal"}
La imposibilidad de observar una variable de respuesta $Y_i$ en la misma unidad y al mismo tiempo para dos condiciones diferentes: $Y_i(t)$ y $Y_i(c)$.
:::

![](images/S1/w_if.png){width="700" height="400" fig-align="center"}
![](images/S1/bart.png){width="700" height="400" fig-align="center"}

Graficamente: 

![](images/S1/plot.png){width="700" height="400" fig-align="center"}

Este es problema de *missing data* para los tratados solo conocemos $Y_i(t)$ y para los controles solo conocemos $Y_i(c)$. 

**¿Qué se puede hacer?**

## *Average Treatment Effect* (ATE)

Veamos los siguientes resultados potenciales: 

::: {.center}

```{r}
#| warning: false
#| message: false
#| echo: false
options(scipen = 999)
# Librerías de trabajo
library(texPreview)
tex <- '
\\documentclass[varwidth, border={ 10 5 10 5 }]{standalone}
\\usepackage{tabu}
\\usepackage{xcolor}
\\begin{document}
    \\begin{tabu}{cccc}
    	  $i$ & $Y^1$ & $Y^0$ & $\\tau$ \\\\ \\hline
        1   & 7     & 1     & 6       \\\\
        2   & 5     & 6     & -1      \\\\
        3   & 5     & 1     & 4       \\\\
        4   & 7     & 8     & -1      \\\\
        5   & 4     & 2     & 2       \\\\
        6   & 10    & 1     & 9       \\\\
        7   & 1     & 10    & -9      \\\\
        8   & 5     & 6     & -1      \\\\
        9   & 3     & 7     & -4      \\\\
        10  & 9     & 8     & 1       \\\\ \\hline
\\\\
	\\end{tabu}
\\end{document}
'
tex_preview(tex_lines=tex, returnType='html', density=300)
```
:::


$$\begin{split}ATE & = \frac{1}{10}\cdot(6-1+4-1+2 \\& \quad +9-9-1-4+1) \\ & = \frac{6}{10}=0.6\end{split}$$

Podemos usar la población $U$ mediante un efecto causal promedio (ATE) como el valor esperado de la diferencia $Y_i(t)-Y_i(c)$ en los $i$'s de $U$:

::: {.center}

```{r}
#| warning: false
#| message: false
#| echo: false
options(scipen = 999)
# Librerías de trabajo
library(texPreview)
tex <- '
\\documentclass[varwidth, border={ 10 5 10 5 }]{standalone}
\\usepackage{tabu}
\\usepackage{xcolor}
\\begin{document}
    \\begin{tabu}{cccccc}
    	  $i$ & $Y^1$ & $Y^0$ & $\\tau$                  & $D_i$ & $Y_i$  \\\\ \\hline
        1   & 7     & \\color{orange}{1}     & \\color{orange}{6}       & 1     & 7    \\\\
        2   & \\color{orange}{5}     & 6     & \\color{orange}{-1}      & 0     & 6    \\\\
        3   & 5     & \\color{orange}{1}     & \\color{orange}{4}       & 1     & 5    \\\\
        4   & \\color{orange}{7}     & 8     & \\color{orange}{-1}      & 0     & 8    \\\\
        5   & 4     & \\color{orange}{2}     & \\color{orange}{2}       & 1     & 4    \\\\
        6   & 10    & \\color{orange}{1}     & \\color{orange}{9}       & 1     & 10   \\\\
        7   & \\color{orange}{1}     & 10    & \\color{orange}{-9}      & 0     & 10   \\\\
        8   & \\color{orange}{5}     & 6     & \\color{orange}{-1}      & 0     & 6    \\\\
        9   & \\color{orange}{3}     & 7     & \\color{orange}{-4}      & 0     & 7    \\\\
        10  & 9     & \\color{orange}{8}     & \\color{orange}{1}       & 1     & 9    \\\\ \\hline
\\\\
	\\end{tabu}
\\end{document}
'
tex_preview(tex_lines=tex, returnType='html', density=300)
```

:::

- Lo que está en naranjo no es observable, por lo que no es posible calcular el ATE directamente, entonces: 

$$
\begin{align}
   ATE & = E[\delta_i] \nonumber      \\
       & = E[Y_i(t) - Y_i(t)] \nonumber \\
       & = E[Y_i(t)] - E[Y_i(c)]        
\end{align}
$$
![](images/S1/treat_control.png){width="700" height="300" fig-align="center"}
Adaptado de [Broockman, D. E., Kalla, J. L., & Sekhon, J. S. (2017). The design of field experiments with survey outcomes: A framework for selecting more efficient, robust, and ethical designs. Political Analysis, 25(4), 435-464.](https://gregoryeady.com/ResearchMethodsCourse/assets/readings/Broockman,%20David%20E.%20et%20al.%20-%202017%20-%20The%20Design%20of%20Field%20Experiments%20with%20Survey%20Outcomes.pdf)

## Supuestos

Si $Y_{i}(D_i)$ es una variable de respuesta observada cuyo valor puede ser $D_i=1$ para $Y_{i}(t)$ o $D_i=0$ para $Y_{i}(c)$, entonces: 

**Independencia**: la asignación al tratamiento es independiente de la variable resultado para tratados ($Y_{i}(t)$) y controles ($Y_{i}(c)$), y de cualquier otra variable en la población, formalmente queda expresado de la siguiente manera: 
$$(Y_{i}(t), Y_{i}(c)) \perp D_{i}$$
En otras palabras:

- $E[Y_i(t)]=E[Y_i(t)|D_i=1]$
- $E[Y_i(c)]=E[Y_i(c)|D_i=0]$
- $ATE=E[Y_i(1)|D_i=1] - E[Y_i(0)|D_i=0]$

Los términos son equivalentes e intercambiables:

- Tratados: $E[Y_i(1)|D_i=1] = E[Y_i(1)|D_i=0] = E[Y_i(1)]$
- Controles: $E[Y_i(0)|D_i=0] = E[Y_i(0)|D_i=1] = E[Y_i(0)]$

En consecuencia la asignación al grupo de tratamiento o control no incide sobre el valor esperado. Por lo tanto, la asignación aleatoria es condición de posibilidad de la independencia y se deduce que, en **los promedios**, la única diferencia entre $(D_{t}$ y $(D_{c}$ corresponde a que un grupo fue tratado y el otro no. En definitiva, se puede estimar el $ATE$ como el efecto promedio del *medicaid* para el grupo tratamiento y en el grupo de control: 

$$\frac{1}{N}\sum_{i=1}^{N} Y_{i}(t) - \frac{1}{N}\sum_{i=1}^{N} Y_{i}(c)$$


**Restricción de exclusión**:  los resultados del experimento dependen únicamente de la exposición al tratamiento $(D_{i}=1)$ y no de la asignación entre grupo de tratamiento y control. En términos formales nos permite identificar el efecto causal. En definitiva se espera que todos los individuos asignados al tratamiento sean expuestos al estímulo, a su vez, los asignados al grupo de control no son expuestos al estímulo:
$$Y_{i}(1,d) = Y_{i}(0,d)$$


**Stable-unit-treatment assumption (SUTVA)**: no hay interferencia (*spillovers*) en la respuesta al tratamiento de un individuo en comparación a otro. En otras palabras, si la observación $i$ se expone al tratamiento $t$, el valor de la variable resultado $Y$ se mantendrá igual sin importar el tipo de asignación ni el tipo de tratamiento que reciban las otras observaciones $i$ (sería problemático que la asignación del seguro a un individuo afectara el resultado de salud en otro individuo). Esto nos garantiza de que **solo existan dos respuestas** ante la condición de tratamiento (asignación), independiente de las otras unidades. Por lo tanto, podemos estimar la causalidad como al diferencia en la variable resultado para el grupo de tratamiento y el grupo de control.

![](images/S1/treat_control2.png){width="500" height="550" fig-align="center"}

Adaptado de [Broockman, D. E., Kalla, J. L., & Sekhon, J. S. (2017). The design of field experiments with survey outcomes: A framework for selecting more efficient, robust, and ethical designs. Political Analysis, 25(4), 435-464.](https://gregoryeady.com/ResearchMethodsCourse/assets/readings/Broockman,%20David%20E.%20et%20al.%20-%202017%20-%20The%20Design%20of%20Field%20Experiments%20with%20Survey%20Outcomes.pdf)

Algunos ejemplos: 

- Salud pública: efecto rebaño.

- Educación: estudiantes pueden compartir su conocimiento con amigos.

- Criminología: la presencia policial puede desplazar la criminalidad a otras áreas.

## La idea del contrafactual 

Pensemos dos escenarios, **¿podemos identificar el efecto?**

- *Comparaciones antes-después*: cotejan los resultados del mismo grupo antes y después de una intervención.

- *Comparaciones de participantes versus no participantes*: comparan los resultados de un grupo que elige participar de la intervención versus otro grupo que elige no participar.

## Correlación vs causalidad 

En muchos estudios e investigaciones, es fácil observar una correlación entre dos variables, como la acción del hombre dentro del vehículo y el movimiento de este, pero eso no significa que una variable cause la otra. La causalidad implica un mecanismo claro que conecta las variables de manera que una provoque la otra, como las personas empujando el vehículo desde fuera.

![](images/S1/causa_efecto.png){width="600" height="550" fig-align="center"}

La pregunta de fondo es **¿la correlación observada es causal?**

Causalidad $\neq$ Asociación:

$E[Y_i(1)] - E[Y_i(0)] \neq E[Y_i(1) | D_i = 1] - E[Y_i(0) | D_i = 0]$

Dos condiciones necesarias: 

1. $E[Y_i(1)|D_i=1]=E[Y_i(1)|D_i=0]=E[Y_i(1)]$
2. $E[Y_i(0)|D_i=0]=E[Y_i(0)|D_i=1]=E[Y_i(0)]$

Si las condiciones 1 y 2 se cumplen entonces: Causalidad $=$ Asociación:

![](images/S1/causa_asociacion.png){width="600" height="450" fig-align="center"}

Pensemos en algunas relaciones:

- ¿El cinturón de seguridad (X) reduce mortalidad por accidentes (Y)?
- ¿La contaminación industrial (X) aumenta la temperatura del planeta (Y)?
- ¿Un mayor nivel educativo del padre (X) aumenta el nivel educativo del hijo?
- ¿Venir a clases (X) mejora mi nota final (Y)?

El concepto clave para responder estas preguntas sobre causalidad es el de **contrafactual o contrafáctico** ¿Qué hubiese pasado en ausencia del tratamiento? El escenario ideal es poder comparar el resultado cuando ocurre y cuando no ocurre.

## Aproximación al ATE vía regresión lineal

### Aproximación clásica

Podemos obtener una aproximación directa a partir de datos: 

```{r}
#| warning: false
#| message: false
#| echo: true
# Librerías de trabajo
library(dplyr) # Manipulación 
library(tidyr) # Manipulación 
library(broom) # Para manipular objetos
library(Matrix)
library(AER) # Contiene los datos 
library(texreg) # Contiene los datos 

# Extraemos los datos 
data(STAR)
glimpse(STAR)
```

El conjunto de datos del Project STAR (Student/Teacher Achievement Ratio) proviene de un estudio longitudinal de cuatro años financiado por la Asamblea General de Tennessee y llevado a cabo a fines de la década de 1980 por el Departamento de Educación del Estado. Este estudio incluyó a más de 5,000 estudiantes de 79 escuelas, asignados aleatoriamente a una de tres intervenciones: clases pequeñas (13 a 17 estudiantes por maestro), clases regulares (22 a 25 estudiantes por maestro), y clases regulares con asistente (22 a 25 estudiantes con un asistente de maestro a tiempo completo). Los docentes también fueron asignados aleatoriamente a los grupos que enseñarían. Las intervenciones comenzaron cuando los estudiantes ingresaron al jardín de infancia y continuaron hasta el tercer grado. Stock y Watson (2007) obtuvieron este conjunto de datos del sitio web del Project STAR.

Vamos a trabajar con una versión sencilla de estos datos: 

```{r}
#| warning: false
#| message: false
#| echo: true
# Procesamos los datos
STAR <- STAR %>% 
  tidyr::drop_na(readk, mathk) %>% 
  mutate(str=if_else(stark=="small", 1, 0)) %>% 
  rowwise() %>% 
  mutate(tscorek=(readk + mathk)) %>% 
  select(str, tscorek, readk, mathk)

# Veamos los datos
glimpse(STAR)
```
Si consideramos la definición: 

$$
\begin{align}
   ATE & = E[\delta_i] \nonumber      \\
       & = E[Y_i(t) - Y_i(t)] \nonumber \\
       & = E[Y_i(t)] - E[Y_i(c)]        
\end{align}
$$
Podemos programar esto: 

```{r}
#| warning: false
#| message: false
#| echo: true
# Definimos la función 
estimador_ATE <- function(data, tratamiento, variable_resultado) {
  # Calcular la media del resultado para el grupo tratado
  Yt <- mean(data[[variable_resultado]][data[[tratamiento]] == 1], na.rm = TRUE)
  
  # Calcular la media del resultado para el grupo de control
  Yc <- mean(data[[variable_resultado]][data[[tratamiento]] == 0], na.rm = TRUE)
  
  # Calcular el ATE
  ATE <- Yt - Yc
  
  # Devolver el ATE
  return(ATE)
}
```

```{r}
#| warning: false
#| message: false
#| echo: true
# Aplicamos los datos
estimador_ATE(STAR, tratamiento = "str", variable_resultado = "tscorek")
estimador_ATE(STAR, tratamiento = "str", variable_resultado = "readk")
estimador_ATE(STAR, tratamiento = "str", variable_resultado = "mathk")
```

Una alternativa a esto: 

```{r}
#| warning: false
#| message: false
#| echo: true
STAR %>%
  t.test(tscorek ~ str, data = .) %>%
  tidy()
```

### Aproximación vía regresión 

Podemos aproximarnos al ATE mediante un modelo de regresión lineal: 

$$
\begin{align}
   Y_i & = Y_i(0)(1 - d_i) + Y_i(1)d_i \\
       & = Y_i(0) + (Y_i(1) - Y_i(0))d_i \\
       & = \mu_{Y(0)} + [\mu_{Y(1)} - \mu_{Y(0)}]d_i + Y_i(0) - \mu_{Y(0)} + [(\mu_{Y(1)} - \mu_{Y(0)}) - (Y_i(0) - \mu_{Y(0)})]d_i     \\
       & = \alpha + \beta d_i + u_i
\end{align}
$$

Donde:

- $(\alpha)$ es el intercepto y es igual a $(\mu_{Y(0)})$.
- $(\beta)$ es $(\mu_{Y(1)} - \mu_{Y(0)})$, es decir, ATE.
- $(u_i = Y_i(0) - \mu_{Y(0)}) si (d_i = 0)$ o $(u_i = Y_i(1) - \mu_{Y(1)})$ si $(d_i = 1)$.

Por ejemplo: 

```{r}
#| warning: false
#| message: false
#| echo: true
#| results: asis
# Definimos y estimamos el modelo 
modelo1 <- lm(tscorek ~ str, data = STAR)
modelo2 <- lm(readk ~ str, data = STAR)
modelo3 <- lm(mathk ~ str, data = STAR)

# Reportamos estos modelos
htmlreg(l=list(modelo1, modelo2, modelo3))
```
**¿Cómo interpretamos estos modelos? ¿Qué limitaciones pueden presentar?**

