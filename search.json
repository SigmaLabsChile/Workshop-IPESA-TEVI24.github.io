[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Técnicas de Evaluación de Impacto de Políticas Públicas en Crimen y Seguridad Ciudadana",
    "section": "",
    "text": "Puede saber más de nosotros en: https://sigmaanalytics.cl/"
  },
  {
    "objectID": "index.html#curso-especializado-en-criminología-y-gestión-de-la-seguridad-ciudadana",
    "href": "index.html#curso-especializado-en-criminología-y-gestión-de-la-seguridad-ciudadana",
    "title": "Técnicas de Evaluación de Impacto de Políticas Públicas en Crimen y Seguridad Ciudadana",
    "section": "Curso especializado en criminología y gestión de la seguridad ciudadana",
    "text": "Curso especializado en criminología y gestión de la seguridad ciudadana\nEste curso analiza las dificultades para estimar efectos causales en ciencias sociales, especialmente en criminología y se introducen estrategias para abordar la causalidad mediante diseños experimentales y cuasi-experimentales.\nEste curso realizará mediante las presentaciones de clases magistrales de expertos en políticas públicas, que mediante sesiones virtuales permitirá a los participantes adquirir nuevos conocimientos teóricos y prácticos sobre la implementación de las principales técnicas vigentes en la evaluación de impacto. Así también, el curso busca generar un espacio donde se desarrolle el pensamiento crítico y de reflexión sobre la evaluación, analizando datos estadísticos, análisis de documentos normativos y estudio de casos prácticos.\nRequisitos: conocimientos básicos de test de hipótesis, regresión lineal y programación en R.\nTendremos tres sesiones:\nSesión 1: Problema fundamental de la inferencia causal y repaso de regresión lineal.\n26/11 de 19:00 – 21:00 hrs\nSesión 2: Diseños experimentales: aleatorización y diseño de bloques.\n28/11 de 19:00 – 21:00 hrs\nSesión 3: Técnicas con datos observacionales: matching y variables instrumentales.\nEstudio personal"
  },
  {
    "objectID": "index.html#metodología",
    "href": "index.html#metodología",
    "title": "Técnicas de Evaluación de Impacto de Políticas Públicas en Crimen y Seguridad Ciudadana",
    "section": "Metodología",
    "text": "Metodología\nClases expositivas y códigos en lenguaje de programación R disponibles para reproducibilidad."
  },
  {
    "objectID": "index.html#evaluaciones",
    "href": "index.html#evaluaciones",
    "title": "Técnicas de Evaluación de Impacto de Políticas Públicas en Crimen y Seguridad Ciudadana",
    "section": "Evaluaciones",
    "text": "Evaluaciones\n\nPrueba de selección múltiple al inicio del curso.\nPrueba de selección múltiple al final del curso."
  },
  {
    "objectID": "index.html#referencias",
    "href": "index.html#referencias",
    "title": "Técnicas de Evaluación de Impacto de Políticas Públicas en Crimen y Seguridad Ciudadana",
    "section": "Referencias",
    "text": "Referencias\nAngrist, J. D. y J. Pischke (2015). Mastering ’Metrics: The Path from Cause to Effect. Princeton University Press.\nCunningham, S. (2021). Causal inference. In Causal Inference. Yale University Press. Versión en inglés: https://mixtape.scunning.com/\nGerber, A. S. y D. P. Green (2012). Field Experiments: Design, Analysis, and Interpretation. New York: W. W. Norton.\nHuntington-Klein, N. (2021). The effect: An introduction to research design and causality. Chapman and Hall/CRC. Versión en inglés: https://theeffectbook.net/index.html\nPearl, J., & Mackenzie, D. (2018). The book of why: the new science of cause and effect. Basic books. Lo puede encontrar aquí.\nStock, J. and Watson, M., Introduction to Econometrics, 3rd edition. (Disponible en Biblioteca SJ-UC)."
  },
  {
    "objectID": "index.html#links-complementarios",
    "href": "index.html#links-complementarios",
    "title": "Técnicas de Evaluación de Impacto de Políticas Públicas en Crimen y Seguridad Ciudadana",
    "section": "Links Complementarios",
    "text": "Links Complementarios\n\nR para Ciencia de Datos: Libro base para el uso de R, aquí podrán ver que la plataforma de Rstudio no es solo para el análisis estadístico, sino que de procesamiento de datos y reporte (versión en español).\nAnalizaR Datos Políticos: Manual con herramientas y tips prácticos para analizar datos políticos.\nUCLA: Espacio para aprender estadística y programación.\nCausal Inference in R: Libro que utiliza una combinación de ejemplos de la medicina, la economía y la tecnología para demostrar que se necesita una pregunta causal clara y la voluntad de ser transparente sobre las suposiciones."
  },
  {
    "objectID": "index.html#comunidades-y-foros",
    "href": "index.html#comunidades-y-foros",
    "title": "Técnicas de Evaluación de Impacto de Políticas Públicas en Crimen y Seguridad Ciudadana",
    "section": "Comunidades y foros",
    "text": "Comunidades y foros\nPara los que alguna vez fuimos nuevos en RStudio sirve bastante ver las preguntas/respuestas de otras personas en las comunidades de R (¡son muy activas!). De hecho, casi todas nuestras preguntas ya fueron respondidas por personas en todo el mundo. No olvidar que la mayoría de estos foros están en inglés:\n\nRStudio Community\nStackoverflow"
  },
  {
    "objectID": "index.html#otros-enlaces-de-interés",
    "href": "index.html#otros-enlaces-de-interés",
    "title": "Técnicas de Evaluación de Impacto de Políticas Públicas en Crimen y Seguridad Ciudadana",
    "section": "Otros enlaces de interés",
    "text": "Otros enlaces de interés\n\nCompendio de links útiles\nConectarse a Github desde R"
  },
  {
    "objectID": "S2.html",
    "href": "S2.html",
    "title": "Sesión 2: Diseños experimentales",
    "section": "",
    "text": "Puede saber más de nosotros en: https://sigmaanalytics.cl/"
  },
  {
    "objectID": "S2.html#modelo-de-resultados-potenciales-neyman-rubin",
    "href": "S2.html#modelo-de-resultados-potenciales-neyman-rubin",
    "title": "Sesión 2: Diseños experimentales",
    "section": "Modelo de resultados potenciales (Neyman-Rubin)",
    "text": "Modelo de resultados potenciales (Neyman-Rubin)\nConsidere una población de \\(i\\) unidades potencialmente expuestas a un tratamiento (causa) o control. La variable \\(D_i\\) nos indicará si la unidad \\(i\\) fue tratada (\\(D_i=t\\)) o no tratada, o sea control, (\\(D_i=c\\)).\nNos interesa evaluar el efecto sobre una variable de respuesta observada que denotaremos como \\(Y_i\\) con dos respuestas potenciales:\n\n\\(Y_i(t)\\) si la unidad fue tratada\n\\(Y_i(c)\\) en caso contrario\n\nDado que \\(Y_i\\) mide el efecto de la causa, entonces, los valores de \\(Y_i\\) son posteriores a la exposición del tratamiento.\nA su vez, denotamos que el modelo causal del tratamiento en una unidad \\(i\\) puede ser expresado como:\n\\[\\delta_i=Y_i(t)-Y_i(c)\\]\nLo interesante del modelo Neyman-Rubin es que el valor de \\(D_i\\) para cada unidad \\(i\\) podría haber sido distinto. Este es el problema.\n\\[Y_i=D_iY_i(t)-(1-D_i)Y_i(c)\\] Donde \\(D_i=1\\) si la persona fue tratada y \\(D_i=0\\) en caso contrario, entonces:\n\\[\\delta_i=(1)Y_i(t)-(1-0)Y_i(c)=Y_i(t)-Y_i(c)\\]\n\n\n\n\n\n\nProblema fundamental de la inferencia causal\n\n\n\nLa imposibilidad de observar una variable de respuesta \\(Y_i\\) en la misma unidad y al mismo tiempo para dos condiciones diferentes: \\(Y_i(t)\\) y \\(Y_i(c)\\) (Holland, 1986).\n\n\nSupuestos:\n\nIndependencia: \\((Y_{i}(t), Y_{i}(c)) \\perp D_{i}\\)\nRestricción de exclusión: \\(Y_{i}(1,d) = Y_{i}(0,d)\\)\nStable-unit-treatment assumption (SUTVA): no hay spillovers"
  },
  {
    "objectID": "S2.html#sesgo-de-selección",
    "href": "S2.html#sesgo-de-selección",
    "title": "Sesión 2: Diseños experimentales",
    "section": "Sesgo de selección",
    "text": "Sesgo de selección\nTenemos tres tipos de efectos causales:\n\nEfecto causal promedio (ATE): es la diferencia como si (what-if) en el SIMCE que esperariamos si pudieramos educar de un modo aleatorio a estudiantes tanto en escuelas municipales y en escuelas privadas.\n\n\\[ATE = E[\\tau_i]=E[Y_i^1-Y_i^0]=E[Y_i^1]-E[Y_i^0]\\]\n\nEfecto causal del tratamiento para los tratados (ATT): es la diferencia como si (what-if) en el SIMCE que esperariamos si pudieramos educar de un modo aleatorio a estudiantes de colegios municipales tanto en escuelas municipales y en escuelas privadas.\n\n\\[ATT=E[\\tau_i|D_i=1]=E[Y_i^1-Y_i^0|D_i=1]=E[Y_i^1|D_i=1]-E[Y_i^0|D_i=1]\\]\n\nEfecto causal del tratamiento para los controles (ATU): es la diferencia como si (what-if) en el SIMCE que esperariamos si pudieramos educar de un modo aleatorio a estudiantes de colegios privados tanto en escuelas municipales y en escuelas privadas.\n\n\\[ATU=E[\\tau_i|D_i=1]=E[Y_i^1-Y_i^0|D_i=1]=E[Y_i^1|D_i=1]-E[Y_i^0|D_i=1]\\] Veamos un ejemplo:\n\n\n\n\n\n\n\n\n\n\n\n\\[\\begin{split}ATE & = \\frac{1}{10}\\cdot(6-1+4-1+2 \\\\& \\quad +9-9-1-4+1) \\\\ & = \\frac{6}{10}=0.6\\end{split}\\]\n\\[\\begin{split}ATT & = \\frac{1}{5}\\cdot(6+4+2+9+1) \\\\ & = \\frac{22}{5}=4.4\\end{split}\\]\n\\[\\begin{split}ATU & = \\frac{1}{5}\\cdot(-1-1-9-1-4) \\\\ & = \\frac{-16}{5}=-3.2\\end{split}\\] Lo que está en naranjo no es observable, por lo que no es posible calcular el ATE directamente, entonces no es posible calcular ATE, ATT o ATU directamente, ya que los parámetros de interés no son observables.\n\n\n\n\n\n\nIdea clave\n\n\n\nLos distintos métodos de estimación de efectos causales persiguen siempre el mismo objetivo: usar información observable para construir un estimador plausible del contrafactual.\n\n\nPodríamos construir nuestras medidas a partir de un estimador de diferencia de medias (SDM) que utiliza la diferencia de promedios entre tratados y no tratados si es que se tiene una muestra aleatoria. Pero tenemos dos problemas:\n\\[\\begin{split}SDM & = E[Y_i|D_i=1]-E[Y_i|D_i=0] \\\\ \\\\ & = E[Y_i^1|D_i=1]-E[Y_i^0|D_i=0]\\color{orange}{+E[Y_i^0|D_i=1]-E[Y_i^0|D_i=1]} \\\\ \\\\ & = \\underset{ATT}{\\underbrace{E[Y_i^1-Y_i^0|D_i=1]}}+\\underset{\\text{Selection Bias}}{\\underbrace{\\big\\{E[Y_i^0|D_i=1]-E[Y_i^0|D_i=0]\\big\\}}}\\end{split}\\] Sea \\(\\pi=E[D_i]\\), entonces:\n\\[\\begin{split}ATE = E[\\tau_i] & = \\pi\\cdot E[\\tau_i|D_i=1]+(1-\\pi)\\cdot E[\\tau_i|D_i=0] \\\\ & = \\pi \\cdot ATT + (1-\\pi)\\cdot ATU \\color{orange}{+ ATT - ATT} \\\\ & = (1-\\pi)\\cdot (ATU-ATT) + ATT \\\\ \\Rightarrow ATT & = ATE+(1-\\pi) \\cdot (ATT-ATU) \\end{split}\\]\nEntonces:\n\\[SDM = ATE+\\underset{\\text{Heterogeneous Treatment Effect Bias}}{\\underbrace{(1-\\pi)\\cdot (ATT-ATU)}}+\\underset{\\text{Selection Bias}}{\\underbrace{\\big\\{E[Y_i^0|D_i=1]-E[Y_i^0|D_i=0]\\big\\}}}\\] - Para que el SDM identifique el \\(ATE\\), tenemos que suponer: \\(E[Y_i^0|D_i]=E[Y_i^0] \\quad \\text{y} \\quad E[\\tau_i|D_i]=E[\\tau_i]\\) - Una condición suficiente es \\((Y_i^0,Y_i^1)\\perp D_i\\)\n¿Cuándo tenemos problemas?\n\nLas personas que reciben un tratamiento suelen ser quienes más lo necesitan \\(Y_i^0\\not\\perp D_i\\).\nLas personas que reciben un tratamiento suelen ser quienes mayores beneficios pueden obtener del tratamiento \\((Y_i^1-Y_i^0)\\not\\perp D_i\\)"
  },
  {
    "objectID": "S2.html#asignación-aleatoria",
    "href": "S2.html#asignación-aleatoria",
    "title": "Sesión 2: Diseños experimentales",
    "section": "Asignación aleatoria",
    "text": "Asignación aleatoria\nLa asignación aleatoria es un procedimiento mediante el cual las unidades en un estudio se asignan al tratamiento de manera imparcial, como lanzar una moneda. Este proceso busca asegurar que la asignación sea independiente de las características de las unidades.\nLa asignación aleatoria asegura que todas las combinaciones posibles de asignación de tratamiento tienen la misma probabilidad de ocurrir.\n\\[Pr(Z | \\Omega) = \\frac{1}{\\Omega}, \\forall Z \\in \\Omega\\]\n\n\n\n\n\nSabemos que:\n\\[SDM = ATE+\\underset{\\text{Heterogeneous Treatment Effect Bias}}{\\underbrace{(1-\\pi)\\cdot (ATT-ATU)}}+\\underset{\\text{Selection Bias}}{\\underbrace{\\big\\{E[Y_i^0|D_i=1]-E[Y_i^0|D_i=0]\\big\\}}}\\]\n\nLa asignación aleatoria de un tratamiento garantiza que \\((Y_i^0,Y_i^1)\\perp D_i\\), con lo cual:\n\n\\(\\underset{ATT}{\\underbrace{E[Y_i^1-Y_i^0|D_i=1]}}=\\underset{ATU}{\\underbrace{E[Y_i^1-Y_i^0|D_i=0]}}=\\underset{ATE}{\\underbrace{E[Y_i^1-Y_i^0]}}\\)\n\\(E[Y_i^0|D_i=1]=E[Y_i^0|D_i=0]\\)\n\nPor lo tanto, si el tratamiento se asigna en forma aleatoria,\n\n\\[SDM = ATE = ATT = ATU\\]\nProcedimiento para Asignación Aleatoria Completa:\n\nDeterminar el número total de sujetos \\(N\\) y el tamaño del grupo de tratamiento \\(m\\).\nGenerar un número aleatorio para cada sujeto.\nOrdenar los sujetos de menor a mayor de acuerdo con el número aleatorio.\nAsignar los primeros \\(m\\) sujetos al grupo de tratamiento.\n\nOtros tipos de asignaciones: no restrigida, restringida (condicional).\nHagamos un ejercicio de simulación:\n\n\nClick para ver el código\nN=100000 #número de observaciones\nY0 &lt;- rnorm(n=N, mean=0, sd=1)# resultado potencial - C\nY1 &lt;- rnorm(n=N, mean=0.2, sd=1)# resultado potencial - T\n\n# Asignación aleatoria del tratamiento\nD=(rnorm(N)&gt;0)\n\n\nGrafiquemos las distribuciones:\n\n\nClick para ver el código\nlibrary(ggplot2)\nlibrary(ggpubr)\n\n# Crear data frames para cada distribución\ndata_Y0 &lt;- data.frame(Outcome = Y0, Group = ifelse(D, \"Treatment\", \"Control\"))\ndata_Y1 &lt;- data.frame(Outcome = Y1, Group = ifelse(D, \"Treatment\", \"Control\"))\n\n# Gráfico de densidad para Y0\nplot_Y0 &lt;- ggplot(data_Y0, aes(x = Outcome, fill = Group)) +\n  geom_density(alpha = 0.5) +\n  geom_vline(aes(xintercept = mean(Outcome[Group == \"Treatment\"])), color = \"red\", linetype = \"dashed\") +\n  geom_vline(aes(xintercept = mean(Outcome[Group == \"Control\"])), color = \"blue\", linetype = \"dashed\") +\n  labs(title = expression(\"Distribución de \" ~ Y[0]), x = \"Outcome\", y = \"Density\") +\n  theme_minimal() +\n  theme(legend.position = \"top\")\n\n# Gráfico de densidad para Y1\nplot_Y1 &lt;- ggplot(data_Y1, aes(x = Outcome, fill = Group)) +\n  geom_density(alpha = 0.5) +\n  geom_vline(aes(xintercept = mean(Outcome[Group == \"Treatment\"])), color = \"red\", linetype = \"dashed\") +\n  geom_vline(aes(xintercept = mean(Outcome[Group == \"Control\"])), color = \"blue\", linetype = \"dashed\") +\n  labs(title = expression(\"Distribución de \" ~ Y[1]), x = \"Outcome\", y = \"Density\") +\n  theme_minimal() +\n  theme(legend.position = \"top\")\n\n# Combinar los gráficos en una fila\nggpubr::ggarrange(plot_Y0, plot_Y1, nrow=1, common.legend = TRUE)\n\n\n\n\n\n\n\n\n\n\n\nClick para ver el código\n#ATE:\nmean(Y1-Y0)\n\n\n[1] 0.2111753\n\n\nClick para ver el código\n#ATT:\nmean(Y1[D==1]-Y0[D==1])\n\n\n[1] 0.2080729\n\n\nClick para ver el código\n#ATU:\nmean(Y1[D==0]-Y0[D==0])\n\n\n[1] 0.2142834\n\n\nPodemos usar el \\(SDM\\) para estimar \\(ATE=ATT=ATU\\):\n\n\nClick para ver el código\nY &lt;- Y1*D+Y0*(1-D)\n\n#SDM\nmean(Y[D==1])-mean(Y[D==0])\n\n\n[1] 0.2064953\n\n\nLo mismo podemos hacer con una regresión:\n\nClick para ver el código\nlibrary(texreg)\nreg &lt;- lm(Y~D)\n\n# Reportamos estos modelos\nhtmlreg(l=list(reg))\n\n\n\nStatistical models\n\n\n\n\n \n\n\nModel 1\n\n\n\n\n\n\n(Intercept)\n\n\n-0.00\n\n\n\n\n \n\n\n(0.00)\n\n\n\n\nDTRUE\n\n\n0.21***\n\n\n\n\n \n\n\n(0.01)\n\n\n\n\nR2\n\n\n0.01\n\n\n\n\nAdj. R2\n\n\n0.01\n\n\n\n\nNum. obs.\n\n\n100000\n\n\n\n\n\n\n***p &lt; 0.001; **p &lt; 0.01; *p &lt; 0.05\n\n\n\n\n¿Qué asumimos en esta estimación?"
  },
  {
    "objectID": "S2.html#balance-y-eficiencia",
    "href": "S2.html#balance-y-eficiencia",
    "title": "Sesión 2: Diseños experimentales",
    "section": "Balance y eficiencia",
    "text": "Balance y eficiencia\nSi la asignación ha sido realmente aleatoria, no solo debiéramos tener \\((Y_i^0,Y_i^1)\\perp D_i\\), sino que además esperaríamos tener \\(X_i\\perp D_i\\) para cualquier variable \\(X_i\\) observada antes del programa. La independencia nos dirá que tanto los resultados potenciales como las covariables son independientes de la asignación de tratamiento: \\((Y_i^0,Y_i^1), X \\perp D_i\\)\nUna forma de verificar que la asignación ha sido realmente aleatoria, es comparar las características observadas en la línea de base entre unidades tratadas y no tratadas. El procedimiento para evaluar balance incluye:\n\nTest de medias\n\n\\[t = \\frac{\\bar{X}_T - \\bar{X}_C}{\\sqrt{\\frac{s_T^2}{n_T} + \\frac{s_C^2}{n_C}}}\\] * Camino rápido: un modelo logístico con la variable \\(D_i\\) como dependiente y todas las variables observadas como independientes.\n\nOmnibus Test: Con base en inferencia por aleatorización, se utiliza un test F para evaluar el balance general de todas las covariables conjuntamente. Esto permite verificar si el conjunto completo de covariables muestra una diferencia significativa en su balance entre los grupos: \\[F = \\frac{\\text{MSB}}{\\text{MSW}}\\]\n\nSi la distribución de \\(X_i\\) es similar en ambos grupos, podemos tomarlo como evidencia de que la aleatorización fue efectiva y por lo tanto ambos grupos son comparables tanto en variables observables como en variables no observables. Sin embargo, existe falta de balance si hay correlación entre la covariable \\(X\\) y la asignación de tratamiento \\(D\\). Esto se traduce en: \\[\\text{Cov}(X, D) \\neq 0\\]\nEn el contexto de experimentos, aunque la inferencia causal no requiere covariables, el uso de variables de control puede ser útil para:\n\nReducir la varianza en los resultados potenciales, al re-escalar la variable dependiente.\nEliminar diferencias observadas entre los grupos de tratamiento y control en análisis de regresión.\nFormar bloques para mejorar el diseño experimental.\n\nEn caso de desbalance, la regresión permite estimar el ATE bajo el control de varias covariables. La relación con el modelo contrafactual es la siguiente:\n\\[\\begin{split}Y_i & = Y_i(0)(1 - d_i) + Y_i(1)d_i\n    \\\\ & = Y_i(0) + (Y_i(1) - Y_i(0))d_i\n    \\\\ & = \\mu_{Y(0)} + [\\mu_{Y(1)} - \\mu_{Y(0)}]d_i + (Y_i(0) - \\mu_{Y(0)}) + [(Y_i(1) - \\mu_{Y(1)}) - (Y_i(0) - \\mu_{Y(0)})]d_i\n    \\\\ & = \\alpha + \\beta d_i + u_i\\end{split}\\]\nDonde:\n\n\\(\\alpha=\\mu_{Y(0)}\\)\n\\(\\beta=\\mu_{Y(1)} - \\mu_{Y(0)}\\) es el ATE\n\\(u_i=Y_i(0) - \\mu_{Y(0)}\\) si \\(d_i=0\\) o \\(u_i=Y_i(1) - \\mu_{Y(1)}\\) si \\(d_i=1\\)"
  },
  {
    "objectID": "S2.html#ejemplo-muralidharan-et-al.-2019",
    "href": "S2.html#ejemplo-muralidharan-et-al.-2019",
    "title": "Sesión 2: Diseños experimentales",
    "section": "Ejemplo: Muralidharan et al. (2019)",
    "text": "Ejemplo: Muralidharan et al. (2019)\nMuralidharan, K., Singh, A., & Ganimian, A. J. (2019). Disrupting education? Experimental evidence on technology-aided instruction in India. American Economic Review, 109(4), 1426-1460.\n¿Puede un software de aprendizaje mejorar los resultados académicos de niños en edad escolar?\nProblema: Brechas académicas entre estudiantes que están en el mismo nivel.\n\n\n\n\n\nMindspark Cal software, desarrollado por Educational Initiatives en India:\n\nCombina videos instructivos, juegos, actividades y evaluación continua\nMaterial de alta calidad diseñado y testeado a lo largo de varios años\nContenido adaptativo, i) se adecúa al nivel del niño y ii) profundiza en áreas en las que el niño parece mantener concepciones erradas.\n\nLa pregunta cobra especial relevancia en el contexto de pandemia, en que la educación a distancia puede ser la única alternativa.\nMás allá del contexto actual, existe un debate en cuanto a si este tipo de tecnologías ayuda al aprendizaje o más bien distrae a los niños.\nDiseño experimental\n\nLa intervención consistió en sesiones de aprendizaje con el software Mindspark Cal realizadas en 3 centros Mindspark\nReclutamiento de alumnos en 5 escuelas\n619 participantes (postulantes).\nAsignación aleatoria:\n\n314 en T\n305 en C\n\nAtrición de 15% para los tratados y de 10% para los controles.\n\n¿Supuestos?\nBalance\n\n\n\n\n\nITT\n¿Por qué un ITT?\n\n\n\n\n\nITT (regresiones)\n\n\n\n\n\nITT (heterogeneidad)"
  },
  {
    "objectID": "S2.html#limitaciones-de-aleatorizar",
    "href": "S2.html#limitaciones-de-aleatorizar",
    "title": "Sesión 2: Diseños experimentales",
    "section": "Limitaciones de aleatorizar",
    "text": "Limitaciones de aleatorizar\n\nLa asignación aleatoria de un tratamiento hace posible la identificación de efectos causales por medio de eliminar el sesgo de selección\nEsto ha llevado a que las evaluaciones experimentales o RCTs (randomized controlled trials) se consideren el estándar de oro de la evaluación de impacto\nPero la asignación aleatoria no siempre es posible:\n\nExisten restricciones éticas, legales y prácticas\nNo podemos aleatorizar los años de escolaridad que recibe un grupo de niños\nNo podemos aleatorizar el barrio en el que viven las familias\nNo podemos aleatorizar la entrega de beneficios sociales otorgados por ley, etc.\n\n\nPara saber si es ético asignar un programa en forma aleatoria, debemos responder las siguientes preguntas:\n\n¿Existen recursos disponibles para ofrecer el programa a todos los interesados?\n¿Es posible distinguir precisamente quiénes necesitan/merecen más un programa?\nA priori, ¿Cuánto sabemos acerca de la efectividad del programa?\nSi no hay suficientes recursos para ofrecer el programa a todos y, hasta cierto punto, no es posible distinguir quién necesita más el programa, entonces se puede argumentar que la asignación aleatoria es lo más justo\nCuando sabemos muy poco acerca de la efectividad de un programa (de modo que no es evidente que T es mejor que C), la asignación aleatoria puede justificarse por los beneficios que traería aprender sobre la efectividad del programa… incluso si los recursos alcanzaran para atender a todos (ejemplo: vacunas).\nEntonces, la aleatorización no es intrínsecamente ética o no ética. Todo depende de la situación."
  },
  {
    "objectID": "S2.html#experimento-ideal",
    "href": "S2.html#experimento-ideal",
    "title": "Sesión 2: Diseños experimentales",
    "section": "Experimento ideal",
    "text": "Experimento ideal\nIncluso si un experimento no es factible, Angrist & Pischke (2009) recomiendan pensar en el “experimento ideal” a la hora de diseñar una evaluación de impacto.\n\nMétodos no experimentales de identificación causal buscan situaciones en las que la asignación del tratamiento sea “as-good-as-random”.\nAlgunos le llaman a estos métodos: métodos cuasi-aleatorios/cusi-experimentales.\n\nVeremos algunos la próxima sesión…"
  },
  {
    "objectID": "S2.html#extra-poder-estadístico-en-un-experimento",
    "href": "S2.html#extra-poder-estadístico-en-un-experimento",
    "title": "Sesión 2: Diseños experimentales",
    "section": "Extra: Poder estadístico en un experimento",
    "text": "Extra: Poder estadístico en un experimento\nProximamente…"
  },
  {
    "objectID": "S1.html",
    "href": "S1.html",
    "title": "Sesión 1: Inferencia causal en ciencias sociales",
    "section": "",
    "text": "Puede saber más de nosotros en: https://sigmaanalytics.cl/"
  },
  {
    "objectID": "S1.html#qué-es-la-inferencia-causal",
    "href": "S1.html#qué-es-la-inferencia-causal",
    "title": "Sesión 1: Inferencia causal en ciencias sociales",
    "section": "¿Qué es la inferencia causal?",
    "text": "¿Qué es la inferencia causal?\nPodemos entender la inferencia causal como el interés por estimar el efecto de los acontencimientos y las decisiones sobre un resultado de interés determinado.\nAlgunos ejemplos:\nZubizarreta, J. R., Cerdá, M., & Rosenbaum, P. R. (2013). Effect of the 2010 Chilean earthquake on posttraumatic stress: reducing sensitivity to unmeasured bias through study design. Epidemiology, 24(1), 79-87.\n\n\n\n\n\nTorche, F. (2011). The effect of maternal stress on birth outcomes: exploiting a natural experiment. Demography, 48, 1473-1491.\n\n\n\n\n\nMuralidharan, K., Singh, A., & Ganimian, A. J. (2019). Disrupting education? Experimental evidence on technology-aided instruction in India. American Economic Review, 109(4), 1426-1460.\n\n\n\n\n\nAunque no siempre podemos hacer experimentos:\nDi Tella, R., & Schargrodsky, E. (2004). Do police reduce crime? Estimates using the allocation of police forces after a terrorist attack. American Economic Review, 94(1), 115–133. https://doi.org/10.1257/000282804322970733\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFundamental\n\nDatos: ¿Cuál es la estrategia de identificación?\nSupuestos: ¿Cuáles son los supuestos que sustentan la causalidad en un estudio?\n\nSin embargo, tendremos algunos inconvenientes…"
  },
  {
    "objectID": "S1.html#problema-fundamental-de-la-inferencia-causal",
    "href": "S1.html#problema-fundamental-de-la-inferencia-causal",
    "title": "Sesión 1: Inferencia causal en ciencias sociales",
    "section": "Problema fundamental de la inferencia causal",
    "text": "Problema fundamental de la inferencia causal\nConsidere una población de \\(i\\) unidades potencialmente expuestas a un tratamiento (causa) o control. La variable \\(D_i\\) nos indicará si la unidad \\(i\\) fue tratada (\\(D_i=t\\)) o no tratada, o sea control, (\\(D_i=c\\)).\nNos interesa evaluar el efecto sobre una variable de respuesta observada que denotaremos como \\(Y_i\\) con dos respuestas potenciales:\n\n\\(Y_i(t)\\) si la unidad fue tratada\n\\(Y_i(c)\\) en caso contrario\n\nDado que \\(Y_i\\) mide el efecto de la causa, entonces, los valores de \\(Y_i\\) son posteriores a la exposición del tratamiento.\nA su vez, denotamos que el modelo causal del tratamiento en una unidad \\(i\\) puede ser expresado como:\n\\[\\delta_i=Y_i(t)-Y_i(c)\\]\nLo interesante del modelo Neyman-Rubin es que el valor de \\(D_i\\) para cada unidad \\(i\\) podría haber sido distinto. Este es el problema.\n\\[Y_i=D_iY_i(t)-(1-D_i)Y_i(c)\\] Donde \\(D_i=1\\) si la persona fue tratada y \\(D_i=0\\) en caso contrario, entonces:\n\\[\\delta_i=(1)Y_i(t)-(1-0)Y_i(c)=Y_i(t)-Y_i(c)\\]\n\n\n\n\n\n\nProblema fundamental de la inferencia causal\n\n\n\nLa imposibilidad de observar una variable de respuesta \\(Y_i\\) en la misma unidad y al mismo tiempo para dos condiciones diferentes: \\(Y_i(t)\\) y \\(Y_i(c)\\).\n\n\n \nGraficamente:\n\n\n\n\n\nEste es problema de missing data para los tratados solo conocemos \\(Y_i(t)\\) y para los controles solo conocemos \\(Y_i(c)\\).\n¿Qué se puede hacer?"
  },
  {
    "objectID": "S1.html#average-treatment-effect-ate",
    "href": "S1.html#average-treatment-effect-ate",
    "title": "Sesión 1: Inferencia causal en ciencias sociales",
    "section": "Average Treatment Effect (ATE)",
    "text": "Average Treatment Effect (ATE)\nVeamos los siguientes resultados potenciales:\n\n\n\n\n\n\n\n\n\n\n\n\\[\\begin{split}ATE & = \\frac{1}{10}\\cdot(6-1+4-1+2 \\\\& \\quad +9-9-1-4+1) \\\\ & = \\frac{6}{10}=0.6\\end{split}\\]\nPodemos usar la población \\(U\\) mediante un efecto causal promedio (ATE) como el valor esperado de la diferencia \\(Y_i(t)-Y_i(c)\\) en los \\(i\\)’s de \\(U\\):\n\n\n\n\n\n\n\n\n\n\n\n\nLo que está en naranjo no es observable, por lo que no es posible calcular el ATE directamente, entonces:\n\n\\[\n\\begin{align}\n   ATE & = E[\\delta_i] \\nonumber      \\\\\n       & = E[Y_i(t) - Y_i(t)] \\nonumber \\\\\n       & = E[Y_i(t)] - E[Y_i(c)]        \n\\end{align}\n\\]  Adaptado de Broockman, D. E., Kalla, J. L., & Sekhon, J. S. (2017). The design of field experiments with survey outcomes: A framework for selecting more efficient, robust, and ethical designs. Political Analysis, 25(4), 435-464."
  },
  {
    "objectID": "S1.html#supuestos",
    "href": "S1.html#supuestos",
    "title": "Sesión 1: Inferencia causal en ciencias sociales",
    "section": "Supuestos",
    "text": "Supuestos\nSi \\(Y_{i}(D_i)\\) es una variable de respuesta observada cuyo valor puede ser \\(D_i=1\\) para \\(Y_{i}(t)\\) o \\(D_i=0\\) para \\(Y_{i}(c)\\), entonces:\nIndependencia: la asignación al tratamiento es independiente de la variable resultado para tratados (\\(Y_{i}(t)\\)) y controles (\\(Y_{i}(c)\\)), y de cualquier otra variable en la población, formalmente queda expresado de la siguiente manera: \\[(Y_{i}(t), Y_{i}(c)) \\perp D_{i}\\] En otras palabras:\n\n\\(E[Y_i(t)]=E[Y_i(t)|D_i=1]\\)\n\\(E[Y_i(c)]=E[Y_i(c)|D_i=0]\\)\n\\(ATE=E[Y_i(1)|D_i=1] - E[Y_i(0)|D_i=0]\\)\n\nLos términos son equivalentes e intercambiables:\n\nTratados: \\(E[Y_i(1)|D_i=1] = E[Y_i(1)|D_i=0] = E[Y_i(1)]\\)\nControles: \\(E[Y_i(0)|D_i=0] = E[Y_i(0)|D_i=1] = E[Y_i(0)]\\)\n\nEn consecuencia la asignación al grupo de tratamiento o control no incide sobre el valor esperado. Por lo tanto, la asignación aleatoria es condición de posibilidad de la independencia y se deduce que, en los promedios, la única diferencia entre \\((D_{t}\\) y \\((D_{c}\\) corresponde a que un grupo fue tratado y el otro no. En definitiva, se puede estimar el \\(ATE\\) como el efecto promedio del medicaid para el grupo tratamiento y en el grupo de control:\n\\[\\frac{1}{N}\\sum_{i=1}^{N} Y_{i}(t) - \\frac{1}{N}\\sum_{i=1}^{N} Y_{i}(c)\\]\nRestricción de exclusión: los resultados del experimento dependen únicamente de la exposición al tratamiento \\((D_{i}=1)\\) y no de la asignación entre grupo de tratamiento y control. En términos formales nos permite identificar el efecto causal. En definitiva se espera que todos los individuos asignados al tratamiento sean expuestos al estímulo, a su vez, los asignados al grupo de control no son expuestos al estímulo: \\[Y_{i}(1,d) = Y_{i}(0,d)\\]\nStable-unit-treatment assumption (SUTVA): no hay interferencia (spillovers) en la respuesta al tratamiento de un individuo en comparación a otro. En otras palabras, si la observación \\(i\\) se expone al tratamiento \\(t\\), el valor de la variable resultado \\(Y\\) se mantendrá igual sin importar el tipo de asignación ni el tipo de tratamiento que reciban las otras observaciones \\(i\\) (sería problemático que la asignación del seguro a un individuo afectara el resultado de salud en otro individuo). Esto nos garantiza de que solo existan dos respuestas ante la condición de tratamiento (asignación), independiente de las otras unidades. Por lo tanto, podemos estimar la causalidad como al diferencia en la variable resultado para el grupo de tratamiento y el grupo de control.\n\n\n\n\n\nAdaptado de Broockman, D. E., Kalla, J. L., & Sekhon, J. S. (2017). The design of field experiments with survey outcomes: A framework for selecting more efficient, robust, and ethical designs. Political Analysis, 25(4), 435-464.\nAlgunos ejemplos:\n\nSalud pública: efecto rebaño.\nEducación: estudiantes pueden compartir su conocimiento con amigos.\nCriminología: la presencia policial puede desplazar la criminalidad a otras áreas."
  },
  {
    "objectID": "S1.html#la-idea-del-contrafactual",
    "href": "S1.html#la-idea-del-contrafactual",
    "title": "Sesión 1: Inferencia causal en ciencias sociales",
    "section": "La idea del contrafactual",
    "text": "La idea del contrafactual\nPensemos dos escenarios, ¿podemos identificar el efecto?\n\nComparaciones antes-después: cotejan los resultados del mismo grupo antes y después de una intervención.\nComparaciones de participantes versus no participantes: comparan los resultados de un grupo que elige participar de la intervención versus otro grupo que elige no participar."
  },
  {
    "objectID": "S1.html#correlación-vs-causalidad",
    "href": "S1.html#correlación-vs-causalidad",
    "title": "Sesión 1: Inferencia causal en ciencias sociales",
    "section": "Correlación vs causalidad",
    "text": "Correlación vs causalidad\nEn muchos estudios e investigaciones, es fácil observar una correlación entre dos variables, como la acción del hombre dentro del vehículo y el movimiento de este, pero eso no significa que una variable cause la otra. La causalidad implica un mecanismo claro que conecta las variables de manera que una provoque la otra, como las personas empujando el vehículo desde fuera.\n\n\n\n\n\nLa pregunta de fondo es ¿la correlación observada es causal?\nCausalidad \\(\\neq\\) Asociación:\n\\(E[Y_i(1)] - E[Y_i(0)] \\neq E[Y_i(1) | D_i = 1] - E[Y_i(0) | D_i = 0]\\)\nDos condiciones necesarias:\n\n\\(E[Y_i(1)|D_i=1]=E[Y_i(1)|D_i=0]=E[Y_i(1)]\\)\n\\(E[Y_i(0)|D_i=0]=E[Y_i(0)|D_i=1]=E[Y_i(0)]\\)\n\nSi las condiciones 1 y 2 se cumplen entonces: Causalidad \\(=\\) Asociación:\n\n\n\n\n\nPensemos en algunas relaciones:\n\n¿El cinturón de seguridad (X) reduce mortalidad por accidentes (Y)?\n¿La contaminación industrial (X) aumenta la temperatura del planeta (Y)?\n¿Un mayor nivel educativo del padre (X) aumenta el nivel educativo del hijo?\n¿Venir a clases (X) mejora mi nota final (Y)?\n\nEl concepto clave para responder estas preguntas sobre causalidad es el de contrafactual o contrafáctico ¿Qué hubiese pasado en ausencia del tratamiento? El escenario ideal es poder comparar el resultado cuando ocurre y cuando no ocurre."
  },
  {
    "objectID": "S1.html#aproximación-al-ate-vía-regresión-lineal",
    "href": "S1.html#aproximación-al-ate-vía-regresión-lineal",
    "title": "Sesión 1: Inferencia causal en ciencias sociales",
    "section": "Aproximación al ATE vía regresión lineal",
    "text": "Aproximación al ATE vía regresión lineal\n\nAproximación clásica\nPodemos obtener una aproximación directa a partir de datos:\n\n\nClick para ver el código\n# Librerías de trabajo\nlibrary(dplyr) # Manipulación \nlibrary(tidyr) # Manipulación \nlibrary(broom) # Para manipular objetos\nlibrary(Matrix)\nlibrary(AER) # Contiene los datos \nlibrary(texreg) # Contiene los datos \n\n# Extraemos los datos \ndata(Guns)\nglimpse(Guns)\n\n\nRows: 1,173\nColumns: 13\n$ year       &lt;fct&gt; 1977, 1978, 1979, 1980, 1981, 1982, 1983, 1984, 1985, 1986,…\n$ violent    &lt;dbl&gt; 414.4, 419.1, 413.3, 448.5, 470.5, 447.7, 416.0, 431.2, 457…\n$ murder     &lt;dbl&gt; 14.2, 13.3, 13.2, 13.2, 11.9, 10.6, 9.2, 9.4, 9.8, 10.1, 9.…\n$ robbery    &lt;dbl&gt; 96.8, 99.1, 109.5, 132.1, 126.5, 112.0, 98.4, 96.1, 105.4, …\n$ prisoners  &lt;int&gt; 83, 94, 144, 141, 149, 183, 215, 243, 256, 267, 283, 307, 3…\n$ afam       &lt;dbl&gt; 8.384873, 8.352101, 8.329575, 8.408386, 8.483435, 8.514000,…\n$ cauc       &lt;dbl&gt; 55.12291, 55.14367, 55.13586, 54.91259, 54.92513, 54.89621,…\n$ male       &lt;dbl&gt; 18.17441, 17.99408, 17.83934, 17.73420, 17.67372, 17.51052,…\n$ population &lt;dbl&gt; 3.780403, 3.831838, 3.866248, 3.900368, 3.918531, 3.925229,…\n$ income     &lt;dbl&gt; 9563.148, 9932.000, 9877.028, 9541.428, 9548.351, 9478.919,…\n$ density    &lt;dbl&gt; 0.0745524, 0.0755667, 0.0762453, 0.0768288, 0.0771866, 0.07…\n$ state      &lt;fct&gt; Alabama, Alabama, Alabama, Alabama, Alabama, Alabama, Alaba…\n$ law        &lt;fct&gt; no, no, no, no, no, no, no, no, no, no, no, no, no, no, no,…\n\n\nLa base de datos Guns es un panel equilibrado que contiene información anual sobre los 50 estados de EE.UU. desde 1977 hasta 1999, diseñada para estudiar la relación entre políticas de control de armas y la criminalidad. El objetivo principal es evaluar cómo las variaciones en las leyes relacionadas con armas de fuego, como restricciones de compra o portación, impactan indicadores de criminalidad, incluidos homicidios, robos y otros delitos violentos. Estos datos permiten analizar patrones longitudinales y entre estados, controlando tanto por características invariables en el tiempo de cada estado como por factores comunes a nivel nacional, ayudando a identificar el impacto causal de las políticas de armas en los resultados de seguridad pública.\nVamos a trabajar con una versión sencilla de estos datos:\n\n\nClick para ver el código\n# Procesamos los datos\nguns &lt;- Guns %&gt;% \n  tidyr::drop_na(law, violent, murder, robbery) %&gt;% \n  mutate(str=if_else(law==\"yes\", 1, 0)) %&gt;% \n  rowwise() %&gt;% \n  select(str, violent, murder, robbery)\n\n# Veamos los datos\nglimpse(guns)\n\n\nRows: 1,173\nColumns: 4\nRowwise: \n$ str     &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ violent &lt;dbl&gt; 414.4, 419.1, 413.3, 448.5, 470.5, 447.7, 416.0, 431.2, 457.5,…\n$ murder  &lt;dbl&gt; 14.2, 13.3, 13.2, 13.2, 11.9, 10.6, 9.2, 9.4, 9.8, 10.1, 9.3, …\n$ robbery &lt;dbl&gt; 96.8, 99.1, 109.5, 132.1, 126.5, 112.0, 98.4, 96.1, 105.4, 111…\n\n\nSi consideramos la definición:\n\\[\n\\begin{align}\n   ATE & = E[\\delta_i] \\nonumber      \\\\\n       & = E[Y_i(t) - Y_i(t)] \\nonumber \\\\\n       & = E[Y_i(t)] - E[Y_i(c)]        \n\\end{align}\n\\] Podemos programar esto:\n\n\nClick para ver el código\n# Definimos la función \nestimador_ATE &lt;- function(data, tratamiento, variable_resultado) {\n  # Calcular la media del resultado para el grupo tratado\n  Yt &lt;- mean(data[[variable_resultado]][data[[tratamiento]] == 1], na.rm = TRUE)\n  \n  # Calcular la media del resultado para el grupo de control\n  Yc &lt;- mean(data[[variable_resultado]][data[[tratamiento]] == 0], na.rm = TRUE)\n  \n  # Calcular el ATE\n  ATE &lt;- Yt - Yc\n  \n  # Devolver el ATE\n  return(ATE)\n}\n\n\n\n\nClick para ver el código\n# Aplicamos los datos\nestimador_ATE(guns, tratamiento = \"str\", variable_resultado = \"violent\")\n\n\n[1] -161.1868\n\n\nClick para ver el código\nestimador_ATE(guns, tratamiento = \"str\", variable_resultado = \"murder\")\n\n\n[1] -3.145532\n\n\nClick para ver el código\nestimador_ATE(guns, tratamiento = \"str\", variable_resultado = \"robbery\")\n\n\n[1] -84.43699\n\n\nUna alternativa a esto:\n\n\nClick para ver el código\nguns %&gt;%\n  t.test(violent ~ str, data = .) %&gt;%\n  tidy()\n\n\n# A tibble: 1 × 10\n  estimate estimate1 estimate2 statistic  p.value parameter conf.low conf.high\n     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1     161.      542.      381.      8.24 1.06e-15      613.     123.      200.\n# ℹ 2 more variables: method &lt;chr&gt;, alternative &lt;chr&gt;\n\n\n\n\nAproximación vía regresión\nPodemos aproximarnos al ATE mediante un modelo de regresión lineal:\n\\[\n\\begin{align}\n   Y_i & = Y_i(0)(1 - d_i) + Y_i(1)d_i \\\\\n       & = Y_i(0) + (Y_i(1) - Y_i(0))d_i \\\\\n       & = \\mu_{Y(0)} + [\\mu_{Y(1)} - \\mu_{Y(0)}]d_i + Y_i(0) - \\mu_{Y(0)} + [(\\mu_{Y(1)} - \\mu_{Y(0)}) - (Y_i(0) - \\mu_{Y(0)})]d_i     \\\\\n       & = \\alpha + \\beta d_i + u_i\n\\end{align}\n\\]\nDonde:\n\n\\((\\alpha)\\) es el intercepto y es igual a \\((\\mu_{Y(0)})\\).\n\\((\\beta)\\) es \\((\\mu_{Y(1)} - \\mu_{Y(0)})\\), es decir, ATE.\n\\((u_i = Y_i(0) - \\mu_{Y(0)}) si (d_i = 0)\\) o \\((u_i = Y_i(1) - \\mu_{Y(1)})\\) si \\((d_i = 1)\\).\n\nPor ejemplo:\n\nClick para ver el código\n# Definimos y estimamos el modelo \nmodelo1 &lt;- lm(violent~ str, data = guns)\nmodelo2 &lt;- lm(murder ~ str, data = guns)\nmodelo3 &lt;- lm(robbery ~ str, data = guns)\n\n# Reportamos estos modelos\nhtmlreg(l=list(modelo1, modelo2, modelo3))\n\n\n\nStatistical models\n\n\n\n\n \n\n\nModel 1\n\n\nModel 2\n\n\nModel 3\n\n\n\n\n\n\n(Intercept)\n\n\n542.24***\n\n\n8.43***\n\n\n182.34***\n\n\n\n\n \n\n\n(10.98)\n\n\n(0.25)\n\n\n(5.59)\n\n\n\n\nstr\n\n\n-161.19***\n\n\n-3.15***\n\n\n-84.44***\n\n\n\n\n \n\n\n(22.27)\n\n\n(0.50)\n\n\n(11.35)\n\n\n\n\nR2\n\n\n0.04\n\n\n0.03\n\n\n0.05\n\n\n\n\nAdj. R2\n\n\n0.04\n\n\n0.03\n\n\n0.04\n\n\n\n\nNum. obs.\n\n\n1173\n\n\n1173\n\n\n1173\n\n\n\n\n\n\n***p &lt; 0.001; **p &lt; 0.01; *p &lt; 0.05\n\n\n\n\n¿Cómo interpretamos estos modelos? ¿Qué limitaciones pueden presentar?"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "S3.html",
    "href": "S3.html",
    "title": "Sesión 3: Técnicas cuasi-experimentales",
    "section": "",
    "text": "Puede saber más de nosotros en: https://sigmaanalytics.cl/"
  },
  {
    "objectID": "S3.html#el-estimador-ingenuo",
    "href": "S3.html#el-estimador-ingenuo",
    "title": "Sesión 3: Técnicas cuasi-experimentales",
    "section": "El estimador ingenuo",
    "text": "El estimador ingenuo\nLa diferencia simple de medias observadas para personas tratadas y no tratadas se llama el estimador ingenuo (Naive estimator) del efecto de un tratamiento:\n\\[\\tau^{N} = E[Y_{1i}|T]- E[Y_{0i}|C]\\] Donde:\n\n\\(E[Y_{1i}|T]\\): Promedio del resultado bajo tratamiento para la persona \\(i\\) en el grupo de tratamiento\n\\(E[Y_{0i}|C]\\): Promedio del resultado bajo control para la persona \\(i\\) en el grupo de control\n\n¿Podemos observar ambos términos \\(E[Y_{1i}|T]\\) y \\(E[Y_{0i}|C]\\)?\nRecuerde que el ATE: \\[\\tau^{ATE} = E[Y_{1i}] - E[Y_{0i}]\\]\nUsar el estimador ingenuo para obtener ATE asume entonces:\n\n\\(E[Y_{1i}]=E[Y_{1i}|T]\\)\n\\(E[Y_{0i}]=E[Y_{0i}|C]\\)\n\nEsto no toma en cuenta cómo los individuos llegaron a pertenecer a esos grupos. Este supuesto implica que el estimador es ingenuo porque ignora el problema de selección."
  },
  {
    "objectID": "S3.html#el-problema-de-la-autoselección",
    "href": "S3.html#el-problema-de-la-autoselección",
    "title": "Sesión 3: Técnicas cuasi-experimentales",
    "section": "El problema de la autoselección",
    "text": "El problema de la autoselección\nLa asignación a los grupos no es aleatoria, sino que depende de características observables o no observables de los individuos. Esto afecta la asunción de ignorabilidad o de independencia condicional, que requiere que el tratamiento sea independiente del potencial resultado.\n\nEl problema de selección se genera principalmente porque sólo podemos observar algunas personas bajo tratamiento\nLas personas que participan en un programa son diferentes a aquellas que no participan\nLas personas que participan en un programa son también diferentes a si mismas previo al inicio del programa\n\n¿Ejemplos?\nLa pregunta clave detrás del problema de selección es: ¿Por qué estas personas fueron tratadas y otras no?\n\n\n\n\n\n\nProblema de la autoselección\n\n\n\nBajo el problema de selección, los supuesto detrás del estimador ingenuo son cuestionables: Los resultados para los individuos no tratados son probablemente un mal estimador del estado contrafactual de estos mismos individuos.\n\n\nTenemos dos tipos de autoselección:\n\nSelección en Observables: Participantes son diferentes a los no participantes en características observables, i.e. edad o nivel de educación. Estas características son medibles y por eso las llamamos observables.\nSelección en No-Observables: Participantes son diferentes a los no participantes en características no observables, i.e. aversión al riesgo, habilidad inherente, motivación. En general no tenemos o no podemos medir estas variables y tenerlas en nuestros datos."
  },
  {
    "objectID": "S3.html#métodos-para-abordar-el-problema-de-la-autoselección",
    "href": "S3.html#métodos-para-abordar-el-problema-de-la-autoselección",
    "title": "Sesión 3: Técnicas cuasi-experimentales",
    "section": "Métodos para abordar el problema de la autoselección",
    "text": "Métodos para abordar el problema de la autoselección\nEl estimador ingenuo tiene supuestos fuertes que no se sostienen y son comunes:\n\nComparar un mismo grupo antes y después del programa\nComparar en un mismo periodo personas en distintos grupos\n\n¿Qué métodos utilizar para poder corregir este problema?\n\nSelección en observables\n\nOLS o MICO (control estadístico)\nMatching y Propensity Score Matching\n\nSelección en No-observables\n\nDatos de panel y diferencias en diferencias\nVariables instrumentales\nRegresión discontinua"
  },
  {
    "objectID": "S3.html#dags",
    "href": "S3.html#dags",
    "title": "Sesión 3: Técnicas cuasi-experimentales",
    "section": "DAGS",
    "text": "DAGS\nUn DAG (Directed Acyclic Graph) es una representación gráfica utilizada en estadística causal para modelar relaciones de dependencia y causalidad entre variables.\n\nDirigido (Directed): Las flechas indican una dirección causal de una variable hacia otra (causa → efecto).\nAcrónimo (Acyclic): No hay ciclos en el gráfico; es decir, no puedes empezar en un nodo y volver al mismo nodo siguiendo las flechas.\nNodos: Representan las variables.\nAristas (Edges): Representan relaciones causales directas entre variables.\n\n\n\n\n\n\n\nHay un camino directo desde D a Y que representa un efecto causal.\nPero también hay un segundo camino desde D a Y llamado el “camino de la puerta trasera”\nEsto crea correlaciones espurias entre D y Y (sesgo por variable omitida)"
  },
  {
    "objectID": "S3.html#matching",
    "href": "S3.html#matching",
    "title": "Sesión 3: Técnicas cuasi-experimentales",
    "section": "Matching",
    "text": "Matching\n\nIdea general\nA veces sabemos que los resultados potenciales son independientes del tratamiento (D) condicional en ciertas características observables (X) \\[(Y^1, Y^0) \\perp \\!\\!\\! \\perp D | X\\]\nEsto quiere decir que el valor de \\(Y^1\\) e \\(Y^0\\) son iguales para tratamiento y control para cada valor de \\(X\\) \\[E[Y^1|D=1, X]=E[Y^1|D=0, X]\\]\n\\[E[Y^0|D=1, X]=E[Y^0|D=0, X]\\]\nVeamos un ejemplo de Tabaquismo y cancer de pulmón:\n\n\n\n\n\n\n¿Qué sugiere la Tabla?\n¿Creemos que \\(E[Y^1|Cigarette)]=E[Y^1|Pipe)]=E[Y^1|Cigar)]\\) y \\(E[Y^0|Cigarette)]=E[Y^0|Pipe)]=E[Y^0|Cigar)]\\)?\n\nConsidere que la gente mayor tiene mayor probabilidad de fumar pipa y puro:\n\n\n\n\n\n\nPodemos condicionar en edad de tal manera que la distribución de edad sea idéntica en el grupo de tratamiento y control.\n\nSubclassification: ¿Cuál es la mortalidad ajustada de los fumadores, de manera que tengan la misma distribución etaria de quienes fuman pipa y puro?\n\n\n\n\n\n\n\n\n\n\n¿Qué variables deberíamos utilizar para este ajuste?\n\n\nSupuestos de identificación causal\n\nIndependencia condicional: La asignación al tratamiento (\\(D\\)) es independiente de los resultados potenciales (\\(Y^1, Y^0\\)). Cualquier diferencia en los resultados entre tratados y no tratados puede explicarse completamente por las covariables \\(X\\), y no hay confusión residual. \\[(Y^1, Y^0) \\perp \\!\\!\\! \\perp D | X\\]\nZona de soporte comun: Para cualquier valor de las covariables \\(X\\), existe una probabilidad positiva de estar en el grupo tratado (D=1) y en el no tratado (D=0). \\[0&lt;Pr(D=1|X)&lt;1\\]\n\nA partir de estos dos supuestos podemos obtener la siguiente identidad: \\[E[Y^1-Y^0| X]=E[Y|X,D=1]-E[Y|X, D=0]\\]\nMatching exacto\nEl estimador de Matching \\(\\hat \\beta_{ATT}\\) utilizando como contrafactual los resultados de individuos del grupo de control que son similares en sus observables.\nPromedia la diferencia entre el resultado observado en los tratados y el promedio de los resultados emparejados de los no tratados. Estima el efecto del tratamiento específicamente en aquellos que recibieron el tratamiento.\n\\[\\hat\\beta_{ATT}=\\frac{1}{N_T}\\sum_{D_i=1}\\left(Y_i\\left[\\frac{1}{M}\\sum^M_{m=1}Y_{jm(1)}\\right]\\right)\\] Calcula la diferencia promedio ponderada entre los tratados y no tratados ajustando por el contrafactual promedio. Estima el efecto promedio del tratamiento en toda la población, no solo en los tratados.\n\\[\\hat\\beta_{ATE}=\\frac{1}{N_T}\\sum^N_{i=1}(2D_i-1)\\left(Y_i-\\left[\\frac{1}{M}\\sum^M_{m=1}Y_{jm(1)}\\right]\\right)\\]\nUn ejemplo\n\n\n\n\n\n\n¿Cual es la edad promedio de los capacitados y de los no capacitados?\n¿Son comparables ambos grupos?\nHaga un exact matching en edad, ¿Cuál es el impacto del programa?\n\n\n\nLa maldición de la dimensionalidad\nEn el ejemplo anterior era fácil encontrar un match con la misma edad, pero esto no es siempre así. A medida que crece el número de variables incluidas en \\(X\\), se hace cada vez más difícil encontrar parejas. A esto se le conoce como la maldición de la dimencionalidad.\n\n\n\n\n\n\n\n\n\n\nMatching aproximado\n\nEn lugar de buscar parejas en el mismo estrato (con las mismas características), buscamos parejas con características similares\nUna posibilidad es usar al vecino más cercano-\nSi \\(X\\) es el ingreso de los padres, y una persona tratada tiene padres con ingresos de CLP1.123, su match puede ser la unidad de control cuyos padres tienen el ingreso más cercano a CLP1.123 (por ejemplo, CLP1.380)\nTambién se puede usar los n vecinos más cercanos.\n\n¿Qué pasa si \\(X\\) tiene varias dimensiones?\n\n\\(X\\) podría incluir edad, ingreso de los padres, región, etc.\nEn estos casos no es obvia la manera de identificar al vecino más cercano\nPara encontrar un match necesitamos definir una métrica de distancia\nLa más simple es la distancia euclideana: \\[\\begin{split}||X_i-X_j|| & = \\sqrt{(X_i-X_j)'(X_i-X_j)} \\\\ & = \\sqrt{\\sum_{k=1}^K(X^k_i-X^k_j)^2}\\end{split}\\]\nOtra métrica común es la distancia euclideana normalizada que le da un peso mayor a las dimensiones con menor varianza: \\[\\begin{split}||X_i-X_j|| & = \\sqrt{(X_i-X_j)'\\hat V^{-1}(X_i-X_j)} \\\\ & = \\sqrt{\\sum_{k=1}^K\\frac{(X^k_i-X^k_j)^2}{\\hat \\sigma^2_k}}\\end{split}\\]\nFinalmente, la distancia de Mahalanobis que normaliza usando la matriz de varianza-covarianza de \\(X\\): \\[\\begin{split}||X_i-X_j|| & = \\sqrt{(X_i-X_j)'\\hat \\Sigma_X^{-1}(X_i-X_j)} \\end{split}\\]\n\nUsando métricas como las anteriores, podemos identificar al vecino más cercano o a los \\(n\\) vecinos más cercanos-\nHay muchas otras medidas de distancia. Lo bueno es que ya hay paquetes y algoritmos programados para realizar esto.\n\n\nPropensity Score Matching (PSM)\nEl propensity score es la probabilidad de recibir un tratamiento condicional en \\(X\\): \\[p(X_i) = Pr(D_i=1|X_i)\\] - Rosembaum & Rubin (1983) muestran que el propensity score es un balancing score, es decir: \\[Pr(D_i=1|X_i,p(X_i))=Pr(D_i=1|p(X_i))\\]\nImplementación: podemos estimar en dos etapas:\n\nEn una primera etapa se estima el propensity score usando un modelo probit o logit.\nEn una segunda etapa, se hace un matching aproximado en base a \\(\\hat p(X_i)\\)\nEl método sigue descansando en el supuesto de independencia condicional. Si el supuesto no se cumple, PSM no identifica efectos causales.\n\nEjemplo: NSW job-training program\n\nEl NSW fue un programa de capacitación laboral implementado en EE.UU. a mediados de los 70 y garantizaba empleo por 9 a 18 meses, además de sesiones de acompañamiento.\nLos trabajadores recibían un sueldo algo menor que el de mercado, pero con posibilidades de aumentarlo en base a desempeño y asistencia. Luego de finalizado el período los trabajadores debían buscar empleo por su cuenta.\nLos cupos del programa eran limitados y se asignaron en forma aleatoria, lo que permitió una evaluación experimental.\nEl programa aumentó el ingreso de los participantes entre USD900 (Lalonde, 1986) y USD1.800 (Dehejia and Whaba, 2002).\n\nLalonde (1986) aprovechó la disponibilidad de este experimento para comparar los resultados experimentales con otros métodos no-experimentales que se usaban comúnmente en la época. Además del grupo de control experimental, Lalonde construyó otros grupos de comparación usando datos de la Current Population Survey (CPS) y de la Panel Survey of Income Dynamics (PSID). A partir de estas muestras el paper compara los resultados experimentales (insesgados) con resultados no experimentales.\n\n\n\n\n\nEl resultado de Lalonde se recibió como una alerta para la interpretación de estudios no-experimentales y el paper empujó el desarrollo de evaluaciones experimentales.\nDehejia & Wahba (1999) señalaron que cuando uando existe sesgo de selección, es común que las características de base difieran entre individuos tratados y no tratados. Ellos llamaron la atención sobre el hecho de que los grupos de comparación no experimentales utilizados por Lalonde diferían considerablemente del grupo de tratamiento, lo que podría sesgar sus resultados.\nSabemos que la diferencia simple de medias entre tratados y no tratados es problemática producto del sesgo de selección: \\[E[Y^0_i|D_i=1]\\neq E[Y^0_i|D_i=0]\\] ¿Por qué podríamos tener sesgo de selección en el caso del programa de capacitación NSW?\n\n\n\n\n\nUsando los mismos datos que Lalonde (1986) (además de otras muestras), Dehejia & Wahba (1999) re-estimaron el efecto del programa usando propensity score.\n\n\n\n\n\nBalance usando la muestra de matches:\n\n\n\n\n\nEstimaciones:\n\n\n\n\n\n\n\nPropensity Score Weighting\nFigura realizada por Estrin (2021):\n\n\n\n\n\nEl estimador de propensity score weighting para el ATT es el siguiente:\n\\[\\hat\\tau_{att}^{psw} = \\frac{1}{N_T}\\sum_iY_i\\cdot \\frac{D_i-P(X_i)}{1- P(X_i)}\\]\n\nEn este caso, las unidades tratadas reciben una ponderación de 1.\nLas unidades no tratadas, por su parte, reciben una ponderación \\(\\frac{P(X_i)}{1-P(X_i)}\\).\nA nivel intuitivo, la idea es que luego de la ponderación, el grupo de comparación sea similar al grupo de tratamiento.\nPara esto se da mayor ponderación a unidades que son “escasas” en el grupo de control en comparación con el grupo de tratamiento.\n\n\n\nConsideraciones finales\n\nLa popularidad del matching depende bastante de la disciplina.La mayoría de los académicos son escépticos de que el supuesto de CIA se cumpla en la práctica.\nEn general los economistas (y las ciencias sociales en general) están más preocupados de la selección en no observables que la selección en observables, por lo que en la práctica debemos evaluar cada caso en particular para decidir si es razonable el supuesto de CIA."
  },
  {
    "objectID": "S3.html#variables-instrumentales-iv",
    "href": "S3.html#variables-instrumentales-iv",
    "title": "Sesión 3: Técnicas cuasi-experimentales",
    "section": "Variables instrumentales (IV)",
    "text": "Variables instrumentales (IV)\n\nIntuición\nSupongamos que nos interesa estudiar el efecto causal de \\(x\\) sobre \\(y\\), representado por \\(\\beta\\) en la siguiente regresión: \\[y_i = \\alpha + \\beta x_i +\\varepsilon_i\\]\nSabemos que el estimador \\(\\beta\\) en OLS identifica: \\[\\begin{split}\\hat \\beta_{ols} & =\\frac{Cov(y_i, x_i)}{Var(x_i)} = \\frac{Cov(\\alpha + \\beta x_i + \\varepsilon_i , x_i)}{Var(x_i)} \\\\\\\\& = \\frac{\\beta Var(x_i)+Cov(\\varepsilon_i,x_i)}{Var(x_i)}=\\beta+\\frac{Cov(\\varepsilon_i,x_i)}{Var(x_i)}\\end{split}\\]\nPara que \\(\\hat \\beta_{ols}\\) identifique el verdadero \\(\\beta\\), es necesario suponer que \\(x_i\\) es exógena, esto es: \\[Cov(x_i,\\varepsilon_i)=0\\]\n\n\n\n\n\n\nProblema\n\n\n\nSi tenemos selección sobre no observables, entonces no contamos con una estrategia de condicionamiento que nos permita estimar efectos causales.\n\\[Cov(x_i,\\varepsilon_i)\\neq0\\]\n\n\nFuentes de endogeneidad:\n\nVariables omitidas: una variable no observada afecta de forma simultánea a \\(y_i\\) y \\(x_i\\)\nError de medición: la variable \\(x_i\\) se mide con error\nCausalidad inversa: hay una relación causal entre \\(y_i\\) y \\(x_i\\)\n\nEn este caso podemos utilizar variables instrumentales: una fuente de variación exógena… alguna variable que afecte a \\(x_i\\) pero que no se relacione con \\(\\varepsilon_i\\).\n\n\n\n\n\nEn estos casos podemos utilizar variables instrumentales:\n\nUna variable instrumental \\(Z\\) que afecta a \\(D\\)\n\\(Z\\) afecta a \\(Y\\) “sólo a través” de \\(D\\)\n\\(Z\\) es independiente de las variables que determinan \\(Y\\) excepto \\(D\\) (“restricción de exclusión”)\n\nLas variables instrumentales sólo identifican un efecto causal para cualquier grupo de unidades cuyos comportamientos cambien como resultado del instrumento (cumplidores).\n\n\n\n\n\n\n\nBuenos instrumentos\nSólo se puede contemplar la identificación de un efecto causal mediante variables instrumentales si se puede defender teórica y lógicamente el supuesto de restricción de exclusión (no es comprobable).\n\nBuscar buenos instrumentos en general es difícil\n¿Qué buen instrumento podemos usar para identificar el efecto causal del número de hijos sobre la participación laboral femenina?\n\nUna condición necesaria pero no suficiente para tener un instrumento que pueda satisfacer la restricción de exclusión es que las personas se sientan confundidas cuando se les informa acerca de la relación del instrumento con el resultado.\n¿Qué pensarían si les dijeras que las madres cuyos dos primeros hijos son del mismo género tienen menos empleo fuera del hogar que aquellas cuyos dos hijos tienen una proporción de sexos equilibrada?\n\n\nEfectos de tratamiento homogéneos\nSea el verdadero modelo de los ingresos a partir de la escolaridad: \\[Y_i=\\alpha + \\beta S_i + \\gamma A_i + \\varepsilon_i\\]\nCon \\(A=E[A_i]\\) y \\(E[\\varepsilon_i|s_i]=E[\\varepsilon_i]=0.\\)\n\n\\(Y_i\\) es el registro de los ingresos\n\\(S_i\\) es la escolaridad medida en años\n\\(A_i\\) es la “habilidad o capacidad” individual\n\\(\\varepsilon\\) es un término de error no correlacionado con la escolaridad o la capacidad.\n\nLa habilidad es una variable no observada, por lo que tenemos la siguiente ecuación: \\[Y_i=\\alpha + \\beta S_i + \\nu_i\\]\nDonde \\(\\nu_i=\\gamma A_i + \\varepsilon_i\\)\nA partir de OLS podemos obtener el siguiente estimador para \\(\\beta\\): \\[\\hat \\beta_{ols}=\\frac{Cov(Y_i, S_i)}{Var(S_i)} = \\frac{Cov(\\beta S_i + \\gamma A_i, S_i)}{Var(S_i)} = \\frac{\\beta Var(S_i)+Cov(A_i,S_i)}{Var(S_i)}=\\beta+\\frac{Cov(A_i,S_i)}{Var(S_i)}\\]\nPara que \\(\\hat \\beta_{ols}\\) identifique el efecto marginal de un año de educación \\(S\\), es necesario suponer que la escolaridad \\(S_i\\) es exógena, esto es:\n\\[Cov(A_i,S_i)=0\\]\n¿Por qué podría no cumplirse el supuesto?\n\nEs probable que el nivel de escolaridad se determine en forma óptima, y que dependa de la habilidad (no observada) \\(A_i\\) y de otros factores, resumidos en \\(\\nu_i\\), por lo tanto:\n\n\\[S_i = S(A_i,\\nu_i)\\]\n\nVariable omitida: Si la escolaridad depende de \\(A_i\\), entonces \\(Cov(S_i,A_i)\\neq 0\\).\n\nEs posible que personas con \\(A_i\\) alto tengan un costo de oportunidad alto de educarse (tienen que sacrificar mayores ingresos) y que por lo tanto se eduquen menos.\nTambién es posible que personas con mayor habilidad tengan mayores facilidades para estudiar y que por esto elijan estudiar durante más años\nEl sesgo podría ir en cualquier dirección\n\nCausalidad inversa: No debiéramos ver un efecto retroactivo desde los ingresos hacia la escolaridad, por lo que la causalidad inversa no debería ser un problema en este caso.\nLo que necesitamos es una fuente de variación exógena… alguna variable que afecte a \\(x_i\\), pero que no se relacione con \\(\\varepsilon_i\\)\nSupongamos por ejemplo que tenemos una variable \\(Z_i\\) que afecta a \\(S_i\\) pero no está correlacionada con \\(A_i\\)\n\nEs decir:\n\n\n\n\n\n\n\\(Cov(Z_i, S_i)\\neq0\\)\n\\(Cov(Z_i, A_i)=0\\)\n\n\n\nEstimador de variables instrumentales\n¿Cuál es la covarianza entre \\(Y_i\\) y \\(A_i\\)? \\[Cov(Y_i,Z_i) = Cov(\\alpha +\\beta S_i + \\gamma A_i + \\varepsilon_i, Z_i)= \\beta\\cdot Cov(S_i, Z_i)+ \\gamma\\cdot\\underset{=0}{\\underbrace{Cov(A_i,Z_i)}}=\\beta\\cdot Cov(S_i, Z_i)\\]\nDe modo que \\[\\hat \\beta_{IV} = \\frac{Cov(Y_i,Z_i)}{Cov(S_i,Z_i)} = \\beta\\]\n\n\nSupuestos de identificación\nRelevancia o First Stage: un instrumento es relevante si efectivamente tiene un efecto sobre la variable endógena \\(S_i\\). \\[Cov(S_i, Z_i)\\neq0\\]\n\n\n\n\n\nEste supuesto es necesario para que \\(\\frac{Cov(y_i,z_i)}{Cov(s_i,z_i)}\\) esté definido.\nRestricción de exclusión: Este supuesto requiere que el instrumento \\(Z_i\\) no afecte directamente el outcome \\(Y_i\\), sino solo por medio de afectar la variable endógena \\(S_i\\).\nEste es un supuesto acerca de la relación entre una variable observada \\((Z_i)\\) y una variable no observable \\((A_i)\\). Como tal, no es posible testearlo.\nPara defender la validez del instrumento es necesario recurrir a argumentos teóricos (no empíricos).\n\n\n\n\n\nIndependencia\nSUTVA: los resultados potenciales de cada persona i no están relacionados con el estado de tratamiento de otros individuos.\nMonotonicidad: la variable instrumental opera (débilmente) en la misma dirección en todas las unidades individuales.\n\n\nMínimos cuadrados en 2 etapas (2SLS)\nEl estimador de variables instrumentales lo podemos escribir como: \\[\\hat \\beta_{IV}=\\frac{Cov(Y_i,Z_i)}{Cov(S_i,Z_i)} = \\frac{Cov(Y_i,Z_i)/Var(Z_i)}{Cov(S_i,Z_i)/Var(Z_i)}= \\frac{\\hat \\beta_{ols}^{y,z}}{\\hat \\beta_{ols}^{s,z}}\\] - Es decir, el estimador de IV es igual a la división entre:\n\nEl estimador OLS de una regresión de \\(Y_i\\) en \\(Z_i\\) (forma reducida)\nEl estimador de OLS de una regresión de \\(S_i\\) en \\(Z_i\\) (primera etapa)\n\nCuando tenemos un único instrumento, \\(\\hat\\beta_{IV}\\) es equivalente al estimador de 2SLS: \\[\\hat \\beta_{IV} = \\frac{Cov(Y_i,Z_i)}{Cov(S_i,Z_i)}=\\frac{Cov(Y_i,\\hat S_i)}{Var(\\hat S_i)}=\\hat \\beta_{2SLS},\\]\nDonde \\(\\hat S_i\\) es el valor predicho de \\(S_i\\) en base a una regresión OLS de \\(S_i\\) en \\(Z_i\\): \\[\\hat s_i = \\hat\\pi_0+\\hat\\pi_1 z_i,\\quad \\hat\\pi_1=\\frac{Cov(s_i,z_i)}{Var(z_i)}\\]\n\nEs decir, \\(\\hat \\beta_{2SLS}\\) es el estimador de mínimos cuadrados de una regresión de \\(Y_i\\) en la predicción \\(\\hat S_i\\)\n\n2SLS ayuda a entender la lógica de IV\nEl estimador de IV es equivalente a estimar por OLS una regresión entre \\(Y_i\\) y el valor predicho de \\(S_i\\) en base al instrumento \\(Z_i\\):\n\nEn la primera etapa, estimamos el efecto causal de \\(Z_i\\) sobre \\(A_i\\).\nLuego, usamos el valor predicho de \\(S_i\\) para en una segunda etapa estimar del efecto de \\(\\hat S_i\\) sobre \\(Y_i\\).\n\\(\\hat S_i\\) es una predicción hecha a partir de una variable exógena \\(Z_i\\), por lo que está “limpia” de endogeneidad y por eso podemos usarla para estimar el efecto de \\(S_i\\) sobre \\(Y_i\\).\n\nEn otras palabras, usamos una parte exógena de la variación en \\(S_i\\) para identificar el efecto de \\(S_i\\) sobre \\(Y_i\\).\n\n\nPalabras finales\nQueremos expresar nuestro agradecimiento por su asistencia y activa participación en este curso. Su entusiasmo, compromiso y valiosas contribuciones hicieron de este encuentro un espacio enriquecedor para el intercambio de ideas y el aprendizaje colaborativo.\nPuede saber más de nosotros en: https://sigmaanalytics.cl/"
  }
]